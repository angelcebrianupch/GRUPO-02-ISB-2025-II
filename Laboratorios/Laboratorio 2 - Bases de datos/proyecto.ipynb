{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b00300",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"intro\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üìë Resumen de Datasets y Art√≠culos EMG\\n\",\n",
    "    \"---\\n\",\n",
    "    \"Este notebook organiza diferentes **datasets y art√≠culos cient√≠ficos sobre EMG** (reconocimiento de gestos de la mano y rehabilitaci√≥n post-ACV).\\n\",\n",
    "    \"\\n\",\n",
    "    \"Cada secci√≥n incluye:\\n\",\n",
    "    \"- **T√çTULO**\\n\",\n",
    "    \"- **BREVE DESCRIPCI√ìN DE LA P√ÅGINA**\\n\",\n",
    "    \"- **CONTENIDO DEL LINK** (puntos clave)\\n\",\n",
    "    \"- üîó **Enlace**\\n\",\n",
    "    \"\\n\",\n",
    "    \"<a id=\\\"indice\\\"></a>\\n\",\n",
    "    \"## üóÇÔ∏è √çndice\\n\",\n",
    "    \"1. [GRABMyo (PhysioNet)](#grabmyo)\\n\",\n",
    "    \"2. [sEMG for Basic Hand Movements (UCI)](#semg-basic)\\n\",\n",
    "    \"3. [EMG Data for Gestures (UCI)](#emg-gestures)\\n\",\n",
    "    \"4. [NinaPro DB1](#ninapro)\\n\",\n",
    "    \"5. [EMG Hand-to-Nose (Figshare)](#stroke-hand-nose)\\n\",\n",
    "    \"6. [EMG Hand-Reaching Movements (Mendeley)](#hand-reaching)\\n\",\n",
    "    \"7. [One-Shot Transfer Learning (JNER 2024)](#article-transfer-learning)\\n\",\n",
    "    \"8. [Bilateral Data Fusion (PubMed)](#bilateral-fusion)\\n\",\n",
    "    \"9. [Decoding Intention (JNER 2023)](#decoding-intention)\\n\",\n",
    "    \"10. [Improving Fast EMG Classification (Preprint 2025)](#fast-classification)\\n\",\n",
    "    \"11. [U-Limb (PubMed)](#u-limb)\\n\",\n",
    "    \"\\n\",\n",
    "    \"> ‚úèÔ∏è *Sugerencia:* a√±ade detalles t√©cnicos (n¬∫ de sujetos, canales, fs, protocolo, preprocesamiento recomendado) directamente en cada secci√≥n.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"grabmyo\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1) Gesture Recognition and Biometrics ElectroMyogram (GRABMyo)\\n\",\n",
    "    \"<a id=\\\"grabmyo\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** GRABMyo ‚Äî Gesture Recognition and Biometrics ElectroMyogram (PhysioNet)\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** P√°gina de PhysioNet con un dataset EMG orientado a **reconocimiento de gestos** y **biometr√≠a**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- Registros **EMG multicanal de la mano** con m√∫ltiples gestos etiquetados.\\n\",\n",
    "    \"- √ötil para **clasificaci√≥n de gestos**, **autenticaci√≥n biom√©trica** y **control de pr√≥tesis**.\\n\",\n",
    "    \"- Proporciona **se√±ales crudas**, metadatos y documentaci√≥n.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Acceder al dataset](https://physionet.org/content/grabmyo/1.1.0/)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"semg-basic\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2) sEMG for Basic Hand Movements (UCI)\\n\",\n",
    "    \"<a id=\\\"semg-basic\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** sEMG for Basic Hand Movements ‚Äî UCI ML Repository\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Repositorio UCI con sEMG de **movimientos b√°sicos** de la mano.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- **4 sujetos**, **6 movimientos** b√°sicos.\\n\",\n",
    "    \"- **8 electrodos** en antebrazo; pensado para **clasificaci√≥n supervisada**.\\n\",\n",
    "    \"- Archivos listos para **descarga r√°pida** con descripci√≥n de atributos.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Acceder al dataset](https://archive.ics.uci.edu/dataset/313/semg+for+basic+hand+movements)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"emg-gestures\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3) EMG Data for Gestures (UCI)\\n\",\n",
    "    \"<a id=\\\"emg-gestures\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** EMG Data for Gestures ‚Äî UCI ML Repository\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Dataset UCI con EMG para **gestos de mano**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- Registros de EMG para **m√∫ltiples gestos** y **varios sujetos**.\\n\",\n",
    "    \"- Enfocado en **clasificaci√≥n** y **HCI/BCI**.\\n\",\n",
    "    \"- Informaci√≥n de **formato de archivo** y **atributos**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Acceder al dataset](https://archive.ics.uci.edu/dataset/481/emg+data+for+gestures)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ninapro\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4) NinaPro Database 1\\n\",\n",
    "    \"<a id=\\\"ninapro\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** NinaPro DB1 ‚Äî Non-Invasive Adaptive Prosthetics (HEVS)\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** P√°gina oficial con instrucciones y acceso a **DB1**, base est√°ndar en EMG de gestos.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- **>50 gestos** de mano/mu√±eca en sujetos sanos.\\n\",\n",
    "    \"- M√∫ltiples sensores (**EMG** y **cinem√°tica**).\\n\",\n",
    "    \"- Documentaci√≥n de **protocolo** y citas recomendadas.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Acceder al dataset](https://ninapro.hevs.ch/instructions/DB1.html)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"stroke-hand-nose\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5) EMG data of stroke and healthy subjects (Hand-to-Nose)\\n\",\n",
    "    \"<a id=\\\"stroke-hand-nose\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** EMG de sujetos sanos y post-ACV en gesto mano-a-nariz ‚Äî Figshare\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Repositorio Figshare con **comparativa sano vs post-ACV** en un gesto funcional.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- Se√±ales **EMG de brazo** durante **hand-to-nose**.\\n\",\n",
    "    \"- √ötil para an√°lisis de **co-activaci√≥n** y **asimetr√≠a**.\\n\",\n",
    "    \"- Metadatos de sujetos y tareas.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Acceder al dataset](https://figshare.com/articles/dataset/EMG_data_of_stroke_and_healthy_subjects_when_performing_hand-to-nose_movement/19160963)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"hand-reaching\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6) EMG datasets for hand-reaching movements (Mendeley)\\n\",\n",
    "    \"<a id=\\\"hand-reaching\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** EMG en movimientos de alcance multidireccional ‚Äî Mendeley Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Dataset con **reaching** en m√∫ltiples direcciones para sanos y post-ACV.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- EMG durante **tareas de alcance** con **direcciones variadas**.\\n\",\n",
    "    \"- Comparaci√≥n de **patrones** entre grupos.\\n\",\n",
    "    \"- Archivos organizados y **documentaci√≥n**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Acceder al dataset](https://data.mendeley.com/datasets/f4hh43nd78/1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"article-transfer-learning\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7) Post-stroke hand gesture recognition via one-shot transfer learning (JNER 2024)\\n\",\n",
    "    \"<a id=\\\"article-transfer-learning\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** Reconocimiento post-ACV con redes protot√≠picas ‚Äî JNER\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Art√≠culo con enfoque **few-shot/one-shot**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- Uso de **redes protot√≠picas** para entrenar con **pocas muestras**.\\n\",\n",
    "    \"- Mejora de **generalizaci√≥n** en pacientes post-ACV.\\n\",\n",
    "    \"- Discusi√≥n de **m√©tricas** y **protocolos**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Leer el art√≠culo](https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-024-01398-7)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"bilateral-fusion\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8) A Novel Bilateral Data Fusion for EMG-Driven Deep Learning (PubMed)\\n\",\n",
    "    \"<a id=\\\"bilateral-fusion\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** Fusi√≥n bilateral de EMG para paresia post-ACV ‚Äî PubMed\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Registro PubMed de un art√≠culo que integra **ambos brazos** en el modelado.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- **Fusi√≥n bilateral** para mejorar la **precisi√≥n**.\\n\",\n",
    "    \"- Arquitectura **deep learning** y evaluaci√≥n en post-ACV.\\n\",\n",
    "    \"- Relevante para **rehabilitaci√≥n asistida**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Leer el art√≠culo](https://pubmed.ncbi.nlm.nih.gov/40573553/)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"decoding-intention\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9) Decoding hand & wrist movement intention (JNER 2023)\\n\",\n",
    "    \"<a id=\\\"decoding-intention\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** Decodificaci√≥n de intenci√≥n motora en cr√≥nicos post-ACV ‚Äî JNER\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Art√≠culo sobre **interfaces EMG port√°tiles** para intenci√≥n de movimiento.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- Decodificaci√≥n de **mano** y **mu√±eca**.\\n\",\n",
    "    \"- **Dispositivo portable** con validaci√≥n en hemiparesia.\\n\",\n",
    "    \"- Aplicaci√≥n en **interfaces de rehabilitaci√≥n**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Leer el art√≠culo](https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-023-01301-w)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"fast-classification\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10) Improving Fast EMG Classification for Hand Gesture Recognition (Preprint 2025)\\n\",\n",
    "    \"<a id=\\\"fast-classification\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** An√°lisis de configuraciones para clasificaci√≥n EMG r√°pida ‚Äî Preprints.org\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Preprint con **evaluaci√≥n sistem√°tica** de configuraciones temporales, espaciales y algoritmos.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- Comparativa de **preprocesamiento** y **modelos**.\\n\",\n",
    "    \"- En **sanos** y **post-ACV**.\\n\",\n",
    "    \"- Recomendaciones para **latencia baja** y **precisi√≥n**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Leer el preprint](https://www.preprints.org/manuscript/202505.0374/v1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"u-limb\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 11) U-Limb: Multi-modal, multi-center database (PubMed)\\n\",\n",
    "    \"<a id=\\\"u-limb\\\"></a>\\n\",\n",
    "    \"**T√çTULO:** U-Limb ‚Äî Base multimodal y multic√©ntrica de control de brazo\\n\",\n",
    "    \"\\n\",\n",
    "    \"**BREVE DESCRIPCI√ìN DE LA P√ÅGINA:** Registro PubMed de la base **U-Limb** orientada a control motor de brazo en **sanos** y **post-ACV**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**CONTENIDO DEL LINK:**\\n\",\n",
    "    \"- Datos **EMG**, **cinem√°tica** y **cl√≠nicos**.\\n\",\n",
    "    \"- Protocolos de **tareas motoras**.\\n\",\n",
    "    \"- Orientado a **neurorehabilitaci√≥n** y **benchmarking**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üîó [Acceder al art√≠culo](https://pubmed.ncbi.nlm.nih.gov/34143875/)\\n\",\n",
    "    \"\\n\",\n",
    "    \"[‚¨ÜÔ∏é Volver al √≠ndice](#indice)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"edit-notes\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"### üìù Notas para edici√≥n r√°pida\\n\",\n",
    "    \"- Para **a√±adir detalles** (p. ej., n¬∫ de sujetos, fs, n¬∫ de canales, m√∫sculos, protocolo), edita las listas bajo **CONTENIDO DEL LINK**.\\n\",\n",
    "    \"- Para **citar** en tu informe, guarda aqu√≠ las referencias bibliogr√°ficas y DOI.\\n\",\n",
    "    \"- Si necesitas **c√≥digo de carga/preview** de alg√∫n dataset, inserta una celda de c√≥digo debajo de su secci√≥n (ej., `wfdb`, `pandas`, `matplotlib`).\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3.12.2\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.12.2\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
