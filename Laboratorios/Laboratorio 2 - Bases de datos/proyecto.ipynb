{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3214db25",
   "metadata": {},
   "source": [
    "# âœ¨ Bases de Datos EMG - Grupo 02\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ Tema del Proyecto\n",
    "**Hand Gesture Recognition with EMG Signals**\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ ProblemÃ¡tica  \n",
    "Los pacientes que han sufrido un **ictus** enfrentan serias dificultades para recuperar el control motor fino de sus manos.  \n",
    "Una herramienta que permita **monitorear la recuperaciÃ³n motora** mediante el reconocimiento de gestos con seÃ±ales EMG serÃ­a de gran utilidad.  \n",
    "\n",
    "Actualmente, los sistemas disponibles son:  \n",
    "- ğŸ’° **Costosos**  \n",
    "- âš™ï¸ **Complejos de implementar**  \n",
    "- ğŸš« **Poco accesibles en contextos clÃ­nicos comunes**  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Propuesta de SoluciÃ³n  \n",
    "âœ… Recopilar seÃ±ales **EMG** desde los mÃºsculos del antebrazo.  \n",
    "âœ… Entrenar un **clasificador supervisado** (*KNN, SVM, etc.*).  \n",
    "âœ… Reconocer entre **3 y 5 gestos sencillos de la mano** para su aplicaciÃ³n en rehabilitaciÃ³n.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Objetivos de esta SecciÃ³n (Bases de Datos)\n",
    "\n",
    "ğŸ“‚ **Explorar** repositorios pÃºblicos con seÃ±ales EMG.  \n",
    "ğŸ“Š **Comparar** sus caracterÃ­sticas principales (frecuencia de muestreo, nÃºmero de sujetos, cantidad de gestos).  \n",
    "ğŸ” **Seleccionar** el dataset mÃ¡s adecuado para entrenar y validar el clasificador.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03625bad",
   "metadata": {},
   "source": [
    "# ğŸ“‘ Base de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7bbc7",
   "metadata": {},
   "source": [
    "## 0ï¸âƒ£1ï¸âƒ£ [Gesture Recognition and Biometrics ElectroMyogram (GRABMyo)](https://physionet.org/content/grabmyo/1.1.0/ ) ğŸ“š\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ InformaciÃ³n General\n",
    "- **Nombre completo:** *Gesture Recognition and Biometrics ElectroMyogram (GRABMyo)*  \n",
    "- **Autores:** Ning Jiang, Ashirbad Pradhan, Jiayuan He  \n",
    "- **Publicado en:** PhysioNet (versiÃ³n 1.1.0, junio 7, 2024)  \n",
    "- **DOI:** [10.13026/89dm-f662](https://doi.org/10.13026/89dm-f662)  \n",
    "- **Sujetos:** 43 participantes (23 hombres, 20 mujeres), edad: 24â€“35 aÃ±os  \n",
    "- **Sesiones:** 3 dÃ­as distintos â†’ *129 grabaciones en total*  \n",
    "- **Gestos registrados:** 16 gestos de mano y dedos + reposo  \n",
    "- **Frecuencia de muestreo:** 2048 Hz  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://physionet.org/files/grabmyo/1.1.0/GestureList.JPG?download\" alt=\"gramb_refernce\" height=\"700\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ PropÃ³sito del Dataset\n",
    "El dataset se diseÃ±Ã³ para aplicaciones en:  \n",
    "1. ğŸ” **BiometrÃ­a EMG**: identificaciÃ³n y autenticaciÃ³n personal.  \n",
    "2. âœ‹ **Reconocimiento de gestos**: rehabilitaciÃ³n, prÃ³tesis, control de interfaces y entornos virtuales.  \n",
    "3. ğŸ§ª **Robustez multisesiÃ³n**: evaluar variaciones entre dÃ­as (electrodos, piel, fatiga, etc.).  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© DiseÃ±o Experimental\n",
    "- **Electrodos:** 28 en total (16 antebrazo + 12 muÃ±eca en configuraciÃ³n bipolar).  \n",
    "- **Protocolo:**  \n",
    "  - 17 gestos (16 movimientos + reposo).  \n",
    "  - Cada gesto repetido **7 veces**.  \n",
    "  - DuraciÃ³n: 5 s por gesto + 10 s de descanso.  \n",
    "- **ConfiguraciÃ³n de sesiones:**  \n",
    "  - `Session1/Session2/Session3`  \n",
    "  - Cada una con 43 subcarpetas (un sujeto por carpeta).  \n",
    "  - Archivos de salida: `.dat` y `.hea`.  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://ieee-dataport.org/sites/default/files/styles/home/public/Appendix1_2.jpg?itok=Z4M-sNmQ\" alt=\"gramb_refernce2\" height=\"300\">\n",
    "</p>\n",
    "---\n",
    "\n",
    "## ğŸ“Š CaracterÃ­sticas TÃ©cnicas\n",
    "- **Canales activos:**  \n",
    "  - F1â€“F16 â†’ antebrazo (2 anillos Ã— 8 electrodos).  \n",
    "  - W1â€“W12 â†’ muÃ±eca (2 anillos Ã— 6 electrodos).  \n",
    "  - U1â€“U4 â†’ canales no usados (espaciadores).  \n",
    "- **TamaÃ±o de cada registro:** `10240 x 32` (5 s Ã— 2048 Hz Ã— 32 canales).  \n",
    "- **Archivos extra:**  \n",
    "  - `grabmyo_convert_wfdb_to_mat.py` â†’ conversiÃ³n a MATLAB.  \n",
    "  - `grabmyo_feature_extraction.m` â†’ extracciÃ³n de caracterÃ­sticas.  \n",
    "  - `grabmyo_visualize.py` â†’ visualizaciÃ³n de datos.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Posibles Usos\n",
    "- ğŸ›¡ï¸ **AutenticaciÃ³n biomÃ©trica** â†’ EMG como contraseÃ±a o firma muscular.  \n",
    "- ğŸ†” **IdentificaciÃ³n** â†’ reconocer al usuario entre N sujetos.  \n",
    "- ğŸ¦¾ **Reconocimiento de gestos** â†’ aplicaciones en rehabilitaciÃ³n, prÃ³tesis y control de interfaces.  \n",
    "- ğŸ”„ **AdaptaciÃ³n a electrodos desplazados** â†’ tÃ©cnicas de transferencia y robustez.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a3958",
   "metadata": {},
   "source": [
    "# 0ï¸âƒ£2ï¸âƒ£ [sEMG for Basic Hand Movements â€“ UCI Repository](https://archive.ics.uci.edu/dataset/313/semg+for+basic+hand+movements ) ğŸ“š\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ InformaciÃ³n General\n",
    "- **Nombre completo:** *sEMG for Basic Hand movements*  \n",
    "- **Autores:** Christos Sapsanis, Anthony Tzes, G. Georgoulas  \n",
    "- **Publicado en:** UCI Machine Learning Repository (2014)  \n",
    "- **DOI:** [10.24432/C5TK53](https://doi.org/10.24432/C5TK53)  \n",
    "- **Sujetos:**  \n",
    "  - **Database 1:** 5 sujetos (2 hombres, 3 mujeres, 20â€“22 aÃ±os).  \n",
    "  - **Database 2:** 1 sujeto (hombre, 22 aÃ±os) durante 3 dÃ­as consecutivos.  \n",
    "- **Movimientos:** 6 tipos de agarre manual + reposo.  \n",
    "- **Frecuencia de muestreo:** 500 Hz.  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01836-y/MediaObjects/41597_2022_1836_Fig1_HTML.png\" alt=\"semgrefernce2\" height=\"400\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ PropÃ³sito del Dataset\n",
    "El dataset fue diseÃ±ado para:  \n",
    "1. ğŸ§  **ClasificaciÃ³n de movimientos de la mano** a partir de EMG superficial.  \n",
    "2. ğŸ’ª **AnÃ¡lisis de activaciÃ³n muscular** en movimientos funcionales.  \n",
    "3. ğŸ¦¾ **Aplicaciones biomÃ©dicas** en rehabilitaciÃ³n, prÃ³tesis e interfaces hombre-mÃ¡quina.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© DiseÃ±o Experimental\n",
    "- **Electrodos utilizados:**  \n",
    "  - 2 canales â†’ *Flexor Carpi Ulnaris* y *Extensor Carpi Radialis (longus y brevis)*.  \n",
    "  - Referencia en el antebrazo, fijados con bandas elÃ¡sticas.  \n",
    "- **Sistema de adquisiciÃ³n:**  \n",
    "  - Delsys Bagnoliâ„¢ 2-channel EMG System.  \n",
    "  - NI USB-009 para conversiÃ³n A/D.  \n",
    "- **Filtrado de la seÃ±al:**  \n",
    "  - **Band-pass Butterworth:** 15â€“500 Hz.  \n",
    "  - **Notch:** 50 Hz para eliminar ruido de lÃ­nea.  \n",
    "- **Protocolo:**  \n",
    "  - Cada gesto repetido mÃºltiples veces (30 o 100, segÃºn base).  \n",
    "  - DuraciÃ³n de las pruebas: 5â€“6 s.  \n",
    "  - Los sujetos ajustaban fuerza y velocidad libremente.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ–ï¸ Movimientos Registrados\n",
    "Los 6 gestos corresponden a agarres cotidianos:  \n",
    "1. **Spherical** â†’ agarrar objetos redondos.  \n",
    "2. **Tip** â†’ sujetar objetos pequeÃ±os.  \n",
    "3. **Palmar** â†’ agarrar con palma abierta.  \n",
    "4. **Lateral** â†’ sujetar objetos planos/finos.  \n",
    "5. **Cylindrical** â†’ sostener cilindros.  \n",
    "6. **Hook** â†’ cargar objetos pesados en forma de gancho.  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.researchgate.net/publication/357759649/figure/fig1/AS:11431281122325537@1677270339787/Gestures-performed-in-sEMG-for-Basic-Hand-movements-Data-Set-3.jpg\" alt=\"semgrefernce3\" height=\"300\">\n",
    "</p>\n",
    "---\n",
    "\n",
    "## ğŸ“Š CaracterÃ­sticas del Dataset\n",
    "- **Database 1 (5 sujetos):**  \n",
    "  - 6 gestos Ã— 30 repeticiones Ã— 6 s.  \n",
    "  - Archivos `.mat` con **12 matrices por sujeto** (2 canales Ã— 6 gestos).  \n",
    "  - Cada matriz: **30 filas Ã— 3000 columnas** (seÃ±al en voltaje).  \n",
    "\n",
    "- **Database 2 (1 sujeto, 3 dÃ­as):**  \n",
    "  - 6 gestos Ã— 100 repeticiones Ã— 5 s.  \n",
    "  - Archivos `.mat` por dÃ­a.  \n",
    "  - Cada matriz: **100 filas Ã— 2500 columnas**.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Posibles Usos\n",
    "- ğŸ“ˆ **ClasificaciÃ³n multiclase** â†’ modelos ML para reconocer gestos.  \n",
    "- ğŸ¦¾ **Control de prÃ³tesis** y dispositivos de asistencia.  \n",
    "- ğŸ‹ï¸ **Estudio de variabilidad** â†’ entre sujetos y entre dÃ­as.  \n",
    "- ğŸ›¡ï¸ **Interfaces biomÃ©dicas** â†’ rehabilitaciÃ³n y neuroingenierÃ­a.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d726b",
   "metadata": {},
   "source": [
    "# ğŸ“Š Dataset: EMG Data for Gestures  \n",
    "\n",
    "ğŸ“Œ **DonaciÃ³n:** 06/01/2019  \n",
    "ğŸ“Œ **Repositorio:** UCI Machine Learning Repository  \n",
    "ğŸ“Œ **DOI:** [10.24432/C5ZP5C](https://doi.org/10.24432/C5ZP5C)  \n",
    "ğŸ“Œ **Licencia:** Creative Commons Attribution 4.0 International (CC BY 4.0)  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” DescripciÃ³n general  \n",
    "Este dataset contiene seÃ±ales **EMG crudas** registradas mediante un brazalete **Myo Thalmic**, el cual cuenta con **8 sensores** dispuestos alrededor del antebrazo.  \n",
    "\n",
    "- **Sujetos:** 36 voluntarios  \n",
    "- **Gestos estÃ¡ticos registrados:** 6â€“7 tipos  \n",
    "- **DuraciÃ³n:** Cada gesto fue sostenido **3 segundos**, con **3 segundos de pausa** entre gestos.  \n",
    "- **NÃºmero de instancias:** entre **40,000â€“50,000 registros por archivo** (garantizados al menos 30,000).  \n",
    "- **Tareas posibles:** clasificaciÃ³n de gestos, procesamiento de seÃ±ales biomÃ©dicas, biometrÃ­a.  \n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ InstrumentaciÃ³n y protocolo  \n",
    "- **Dispositivo:** Myo Thalmic Bracelet  \n",
    "- **Sensores:** 8 canales EMG distribuidos en el antebrazo  \n",
    "- **ConexiÃ³n:** Bluetooth a PC  \n",
    "- **Datos adquiridos:** seÃ±ales EMG crudas (sin filtrado previo)  \n",
    "\n",
    "Cada sujeto realizÃ³ **2 series de gestos**:  \n",
    "1. Mano en reposo  \n",
    "2. Mano cerrada en puÃ±o  \n",
    "3. FlexiÃ³n de muÃ±eca  \n",
    "4. ExtensiÃ³n de muÃ±eca  \n",
    "5. DesviaciÃ³n radial  \n",
    "6. DesviaciÃ³n cubital  \n",
    "7. Palma extendida (*no todos los sujetos la realizaron*)  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‚ Estructura de los archivos  \n",
    "Cada archivo de datos contiene **10 columnas**:  \n",
    "\n",
    "1. **Tiempo (ms)**  \n",
    "2â€“9. **Canales EMG** (8 sensores del brazalete)  \n",
    "10. **Etiqueta (gesto):**  \n",
    "   - `0` â†’ sin marcar  \n",
    "   - `1` â†’ mano en reposo  \n",
    "   - `2` â†’ puÃ±o cerrado  \n",
    "   - `3` â†’ flexiÃ³n de muÃ±eca  \n",
    "   - `4` â†’ extensiÃ³n de muÃ±eca  \n",
    "   - `5` â†’ desviaciÃ³n radial  \n",
    "   - `6` â†’ desviaciÃ³n cubital  \n",
    "   - `7` â†’ palma extendida  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š CaracterÃ­sticas del dataset  \n",
    "- **Tipo:** Series temporales  \n",
    "- **Ãrea temÃ¡tica:** Salud y medicina  \n",
    "- **Tarea asociada:** ClasificaciÃ³n  \n",
    "- **Formato de datos:** Texto plano (.txt)  \n",
    "- **Valores faltantes:** No presenta  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‚ Archivos disponibles (ejemplos)  \n",
    "- `1_raw_data_13-11_18.03.16.txt` (4.4 MB)  \n",
    "- `1_raw_data_10-51_07.04.16.txt` (4.5 MB)  \n",
    "- `2_raw_data_13-29_21.03.16.txt` (4.6 MB)  \n",
    "*(73 archivos en total, organizados por sujeto y sesiÃ³n)*  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘©â€ğŸ”¬ Autores  \n",
    "- N. Krilova  \n",
    "- I. Kastalskiy  \n",
    "- V. Kazantsev  \n",
    "- V.A. Makarov  \n",
    "- S. Lobov  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Uso en Python  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6debeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1285158999.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install ucimlrepo\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Instalar la librerÃ­a\n",
    "pip install ucimlrepo\n",
    "\n",
    "# Importar el dataset\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Cargar datos\n",
    "emg_data_for_gestures = fetch_ucirepo(id=481)\n",
    "\n",
    "# SeÃ±ales y etiquetas\n",
    "X = emg_data_for_gestures.data.features\n",
    "y = emg_data_for_gestures.data.targets\n",
    "\n",
    "# Metadatos\n",
    "print(emg_data_for_gestures.metadata)\n",
    "\n",
    "# Variables\n",
    "print(emg_data_for_gestures.variables)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
