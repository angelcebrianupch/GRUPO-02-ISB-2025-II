{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3214db25",
   "metadata": {},
   "source": [
    "# ✨ Bases de Datos EMG - Grupo 02\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Tema del Proyecto\n",
    "**Hand Gesture Recognition with EMG Signals**\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ Problemática  \n",
    "Los pacientes que han sufrido un **ictus** enfrentan serias dificultades para recuperar el control motor fino de sus manos.  \n",
    "Una herramienta que permita **monitorear la recuperación motora** mediante el reconocimiento de gestos con señales EMG sería de gran utilidad.  \n",
    "\n",
    "Actualmente, los sistemas disponibles son:  \n",
    "- 💰 **Costosos**  \n",
    "- ⚙️ **Complejos de implementar**  \n",
    "- 🚫 **Poco accesibles en contextos clínicos comunes**  \n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Propuesta de Solución  \n",
    "✅ Recopilar señales **EMG** desde los músculos del antebrazo.  \n",
    "✅ Entrenar un **clasificador supervisado** (*KNN, SVM, etc.*).  \n",
    "✅ Reconocer entre **3 y 5 gestos sencillos de la mano** para su aplicación en rehabilitación.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Objetivos de esta Sección (Bases de Datos)\n",
    "\n",
    "📂 **Explorar** repositorios públicos con señales EMG.  \n",
    "📊 **Comparar** sus características principales (frecuencia de muestreo, número de sujetos, cantidad de gestos).  \n",
    "🔎 **Seleccionar** el dataset más adecuado para entrenar y validar el clasificador.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03625bad",
   "metadata": {},
   "source": [
    "# 📑 Base de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7bbc7",
   "metadata": {},
   "source": [
    "## 0️⃣1️⃣ [Gesture Recognition and Biometrics ElectroMyogram (GRABMyo)](https://physionet.org/content/grabmyo/1.1.0/ ) 📚\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Información General\n",
    "- **Nombre completo:** *Gesture Recognition and Biometrics ElectroMyogram (GRABMyo)*  \n",
    "- **Autores:** Ning Jiang, Ashirbad Pradhan, Jiayuan He  \n",
    "- **Publicado en:** PhysioNet (versión 1.1.0, junio 7, 2024)  \n",
    "- **DOI:** [10.13026/89dm-f662](https://doi.org/10.13026/89dm-f662)  \n",
    "- **Sujetos:** 43 participantes (23 hombres, 20 mujeres), edad: 24–35 años  \n",
    "- **Sesiones:** 3 días distintos → *129 grabaciones en total*  \n",
    "- **Gestos registrados:** 16 gestos de mano y dedos + reposo  \n",
    "- **Frecuencia de muestreo:** 2048 Hz  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://physionet.org/files/grabmyo/1.1.0/GestureList.JPG?download\" alt=\"gramb_refernce\" height=\"700\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Propósito del Dataset\n",
    "El dataset se diseñó para aplicaciones en:  \n",
    "1. 🔐 **Biometría EMG**: identificación y autenticación personal.  \n",
    "2. ✋ **Reconocimiento de gestos**: rehabilitación, prótesis, control de interfaces y entornos virtuales.  \n",
    "3. 🧪 **Robustez multisesión**: evaluar variaciones entre días (electrodos, piel, fatiga, etc.).  \n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Diseño Experimental\n",
    "- **Electrodos:** 28 en total (16 antebrazo + 12 muñeca en configuración bipolar).  \n",
    "- **Protocolo:**  \n",
    "  - 17 gestos (16 movimientos + reposo).  \n",
    "  - Cada gesto repetido **7 veces**.  \n",
    "  - Duración: 5 s por gesto + 10 s de descanso.  \n",
    "- **Configuración de sesiones:**  \n",
    "  - `Session1/Session2/Session3`  \n",
    "  - Cada una con 43 subcarpetas (un sujeto por carpeta).  \n",
    "  - Archivos de salida: `.dat` y `.hea`.  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://ieee-dataport.org/sites/default/files/styles/home/public/Appendix1_2.jpg?itok=Z4M-sNmQ\" alt=\"gramb_refernce2\" height=\"300\">\n",
    "</p>\n",
    "---\n",
    "\n",
    "## 📊 Características Técnicas\n",
    "- **Canales activos:**  \n",
    "  - F1–F16 → antebrazo (2 anillos × 8 electrodos).  \n",
    "  - W1–W12 → muñeca (2 anillos × 6 electrodos).  \n",
    "  - U1–U4 → canales no usados (espaciadores).  \n",
    "- **Tamaño de cada registro:** `10240 x 32` (5 s × 2048 Hz × 32 canales).  \n",
    "- **Archivos extra:**  \n",
    "  - `grabmyo_convert_wfdb_to_mat.py` → conversión a MATLAB.  \n",
    "  - `grabmyo_feature_extraction.m` → extracción de características.  \n",
    "  - `grabmyo_visualize.py` → visualización de datos.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔎 Posibles Usos\n",
    "- 🛡️ **Autenticación biométrica** → EMG como contraseña o firma muscular.  \n",
    "- 🆔 **Identificación** → reconocer al usuario entre N sujetos.  \n",
    "- 🦾 **Reconocimiento de gestos** → aplicaciones en rehabilitación, prótesis y control de interfaces.  \n",
    "- 🔄 **Adaptación a electrodos desplazados** → técnicas de transferencia y robustez.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a3958",
   "metadata": {},
   "source": [
    "# 0️⃣2️⃣ [sEMG for Basic Hand Movements – UCI Repository](https://archive.ics.uci.edu/dataset/313/semg+for+basic+hand+movements ) 📚\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Información General\n",
    "- **Nombre completo:** *sEMG for Basic Hand movements*  \n",
    "- **Autores:** Christos Sapsanis, Anthony Tzes, G. Georgoulas  \n",
    "- **Publicado en:** UCI Machine Learning Repository (2014)  \n",
    "- **DOI:** [10.24432/C5TK53](https://doi.org/10.24432/C5TK53)  \n",
    "- **Sujetos:**  \n",
    "  - **Database 1:** 5 sujetos (2 hombres, 3 mujeres, 20–22 años).  \n",
    "  - **Database 2:** 1 sujeto (hombre, 22 años) durante 3 días consecutivos.  \n",
    "- **Movimientos:** 6 tipos de agarre manual + reposo.  \n",
    "- **Frecuencia de muestreo:** 500 Hz.  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41597-022-01836-y/MediaObjects/41597_2022_1836_Fig1_HTML.png\" alt=\"semgrefernce2\" height=\"400\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Propósito del Dataset\n",
    "El dataset fue diseñado para:  \n",
    "1. 🧠 **Clasificación de movimientos de la mano** a partir de EMG superficial.  \n",
    "2. 💪 **Análisis de activación muscular** en movimientos funcionales.  \n",
    "3. 🦾 **Aplicaciones biomédicas** en rehabilitación, prótesis e interfaces hombre-máquina.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Diseño Experimental\n",
    "- **Electrodos utilizados:**  \n",
    "  - 2 canales → *Flexor Carpi Ulnaris* y *Extensor Carpi Radialis (longus y brevis)*.  \n",
    "  - Referencia en el antebrazo, fijados con bandas elásticas.  \n",
    "- **Sistema de adquisición:**  \n",
    "  - Delsys Bagnoli™ 2-channel EMG System.  \n",
    "  - NI USB-009 para conversión A/D.  \n",
    "- **Filtrado de la señal:**  \n",
    "  - **Band-pass Butterworth:** 15–500 Hz.  \n",
    "  - **Notch:** 50 Hz para eliminar ruido de línea.  \n",
    "- **Protocolo:**  \n",
    "  - Cada gesto repetido múltiples veces (30 o 100, según base).  \n",
    "  - Duración de las pruebas: 5–6 s.  \n",
    "  - Los sujetos ajustaban fuerza y velocidad libremente.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🖐️ Movimientos Registrados\n",
    "Los 6 gestos corresponden a agarres cotidianos:  \n",
    "1. **Spherical** → agarrar objetos redondos.  \n",
    "2. **Tip** → sujetar objetos pequeños.  \n",
    "3. **Palmar** → agarrar con palma abierta.  \n",
    "4. **Lateral** → sujetar objetos planos/finos.  \n",
    "5. **Cylindrical** → sostener cilindros.  \n",
    "6. **Hook** → cargar objetos pesados en forma de gancho.  \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.researchgate.net/publication/357759649/figure/fig1/AS:11431281122325537@1677270339787/Gestures-performed-in-sEMG-for-Basic-Hand-movements-Data-Set-3.jpg\" alt=\"semgrefernce3\" height=\"300\">\n",
    "</p>\n",
    "---\n",
    "\n",
    "## 📊 Características del Dataset\n",
    "- **Database 1 (5 sujetos):**  \n",
    "  - 6 gestos × 30 repeticiones × 6 s.  \n",
    "  - Archivos `.mat` con **12 matrices por sujeto** (2 canales × 6 gestos).  \n",
    "  - Cada matriz: **30 filas × 3000 columnas** (señal en voltaje).  \n",
    "\n",
    "- **Database 2 (1 sujeto, 3 días):**  \n",
    "  - 6 gestos × 100 repeticiones × 5 s.  \n",
    "  - Archivos `.mat` por día.  \n",
    "  - Cada matriz: **100 filas × 2500 columnas**.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔎 Posibles Usos\n",
    "- 📈 **Clasificación multiclase** → modelos ML para reconocer gestos.  \n",
    "- 🦾 **Control de prótesis** y dispositivos de asistencia.  \n",
    "- 🏋️ **Estudio de variabilidad** → entre sujetos y entre días.  \n",
    "- 🛡️ **Interfaces biomédicas** → rehabilitación y neuroingeniería.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d726b",
   "metadata": {},
   "source": [
    "# 📊 Dataset: EMG Data for Gestures  \n",
    "\n",
    "📌 **Donación:** 06/01/2019  \n",
    "📌 **Repositorio:** UCI Machine Learning Repository  \n",
    "📌 **DOI:** [10.24432/C5ZP5C](https://doi.org/10.24432/C5ZP5C)  \n",
    "📌 **Licencia:** Creative Commons Attribution 4.0 International (CC BY 4.0)  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔎 Descripción general  \n",
    "Este dataset contiene señales **EMG crudas** registradas mediante un brazalete **Myo Thalmic**, el cual cuenta con **8 sensores** dispuestos alrededor del antebrazo.  \n",
    "\n",
    "- **Sujetos:** 36 voluntarios  \n",
    "- **Gestos estáticos registrados:** 6–7 tipos  \n",
    "- **Duración:** Cada gesto fue sostenido **3 segundos**, con **3 segundos de pausa** entre gestos.  \n",
    "- **Número de instancias:** entre **40,000–50,000 registros por archivo** (garantizados al menos 30,000).  \n",
    "- **Tareas posibles:** clasificación de gestos, procesamiento de señales biomédicas, biometría.  \n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Instrumentación y protocolo  \n",
    "- **Dispositivo:** Myo Thalmic Bracelet  \n",
    "- **Sensores:** 8 canales EMG distribuidos en el antebrazo  \n",
    "- **Conexión:** Bluetooth a PC  \n",
    "- **Datos adquiridos:** señales EMG crudas (sin filtrado previo)  \n",
    "\n",
    "Cada sujeto realizó **2 series de gestos**:  \n",
    "1. Mano en reposo  \n",
    "2. Mano cerrada en puño  \n",
    "3. Flexión de muñeca  \n",
    "4. Extensión de muñeca  \n",
    "5. Desviación radial  \n",
    "6. Desviación cubital  \n",
    "7. Palma extendida (*no todos los sujetos la realizaron*)  \n",
    "\n",
    "---\n",
    "\n",
    "## 📂 Estructura de los archivos  \n",
    "Cada archivo de datos contiene **10 columnas**:  \n",
    "\n",
    "1. **Tiempo (ms)**  \n",
    "2–9. **Canales EMG** (8 sensores del brazalete)  \n",
    "10. **Etiqueta (gesto):**  \n",
    "   - `0` → sin marcar  \n",
    "   - `1` → mano en reposo  \n",
    "   - `2` → puño cerrado  \n",
    "   - `3` → flexión de muñeca  \n",
    "   - `4` → extensión de muñeca  \n",
    "   - `5` → desviación radial  \n",
    "   - `6` → desviación cubital  \n",
    "   - `7` → palma extendida  \n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Características del dataset  \n",
    "- **Tipo:** Series temporales  \n",
    "- **Área temática:** Salud y medicina  \n",
    "- **Tarea asociada:** Clasificación  \n",
    "- **Formato de datos:** Texto plano (.txt)  \n",
    "- **Valores faltantes:** No presenta  \n",
    "\n",
    "---\n",
    "\n",
    "## 📂 Archivos disponibles (ejemplos)  \n",
    "- `1_raw_data_13-11_18.03.16.txt` (4.4 MB)  \n",
    "- `1_raw_data_10-51_07.04.16.txt` (4.5 MB)  \n",
    "- `2_raw_data_13-29_21.03.16.txt` (4.6 MB)  \n",
    "*(73 archivos en total, organizados por sujeto y sesión)*  \n",
    "\n",
    "---\n",
    "\n",
    "## 👩‍🔬 Autores  \n",
    "- N. Krilova  \n",
    "- I. Kastalskiy  \n",
    "- V. Kazantsev  \n",
    "- V.A. Makarov  \n",
    "- S. Lobov  \n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Uso en Python  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd6debeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1285158999.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install ucimlrepo\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Instalar la librería\n",
    "pip install ucimlrepo\n",
    "\n",
    "# Importar el dataset\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Cargar datos\n",
    "emg_data_for_gestures = fetch_ucirepo(id=481)\n",
    "\n",
    "# Señales y etiquetas\n",
    "X = emg_data_for_gestures.data.features\n",
    "y = emg_data_for_gestures.data.targets\n",
    "\n",
    "# Metadatos\n",
    "print(emg_data_for_gestures.metadata)\n",
    "\n",
    "# Variables\n",
    "print(emg_data_for_gestures.variables)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
