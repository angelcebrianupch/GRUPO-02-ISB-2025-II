{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb53549",
   "metadata": {},
   "source": [
    "# LSTM / GRU aplicados a se√±ales ECG (EKG)\n",
    "\n",
    "## I. Teor√≠a breve del t√≥pico elegido\n",
    "\n",
    "Las se√±ales ECG (electrocardiogr√°ficas) representan la actividad el√©ctrica del coraz√≥n como una **secuencia temporal** [3].   \n",
    "Por ello, son especialmente adecuadas para modelos que pueden **recordar informaci√≥n del pasado** y relacionarla con el presente [1][2].\n",
    "\n",
    "Las redes neuronales recurrentes (RNN tradicionales) fueron dise√±adas para este prop√≥sito, pero sufren de problemas como:\n",
    "\n",
    "- **Vanishing gradient** (la red ‚Äúolvida‚Äù se√±ales antiguas) \n",
    "- Dificultad para aprender dependencias largas\n",
    "- Poca robustez ante se√±ales ruidosas\n",
    "\n",
    "Para resolver estos problemas surgieron **LSTM** y **GRU**, que se convirtieron en los modelos dominantes en tareas de ECG [1][2][3].\n",
    "\n",
    "---\n",
    "\n",
    "## üß† ¬øQu√© es LSTM?\n",
    "\n",
    "Las **Long Short-Term Memory (LSTM)** son un tipo avanzado de RNN que incorporan un mecanismo interno de memoria [1], permitiendo:\n",
    "\n",
    "- Recordar informaci√≥n a largo plazo  \n",
    "- Controlar qu√© informaci√≥n entra y sale  \n",
    "- Evitar que los gradientes se desvanezcan  \n",
    "\n",
    "Una celda LSTM tiene:\n",
    "\n",
    "### ‚úî Input gate  \n",
    "Decide cu√°nta informaci√≥n nueva se debe incorporar [1].\n",
    "\n",
    "### ‚úî Forget gate  \n",
    "Determina cu√°nta informaci√≥n previa debe olvidarse. Esto es crucial en ECG, donde cada latido tiene estructura similar pero puede contener ruido [3].\n",
    "\n",
    "### ‚úî Output gate  \n",
    "Controla qu√© informaci√≥n se env√≠a a la siguiente capa [1].\n",
    "\n",
    "### ‚úî Cell state (memoria a largo plazo)  \n",
    "Transporta informaci√≥n clave sobre la se√±al card√≠aca [1].\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ ¬øQu√© es GRU?\n",
    "\n",
    "Las **Gated Recurrent Units (GRU)** simplifican la estructura de las LSTM manteniendo un desempe√±o similar.  \n",
    "Tienen solo dos puertas:\n",
    "\n",
    "### ‚úî Update gate  \n",
    "Combina input y forget; controla cu√°nta memoria pasada mantener.\n",
    "\n",
    "### ‚úî Reset gate  \n",
    "Define cu√°ndo olvidar informaci√≥n pasada, √∫til para eventos abruptos en ECG (p.ej., latidos prematuros).\n",
    "\n",
    "Las GRU son m√°s ligeras, entrenan m√°s r√°pido y consumen menos recursos‚Äîideal para dispositivos embebidos.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ù§Ô∏è ¬øPor qu√© LSTM/GRU funcionan tan bien en se√±ales ECG?\n",
    "\n",
    "El ECG tiene patrones temporales complejos [3]:\n",
    "\n",
    "- Ritmo card√≠aco (intervalos RR)\n",
    "- Morfolog√≠a P-QRS-T\n",
    "- Variabilidad card√≠aca\n",
    "- Anomal√≠as espec√≠ficas de arritmias\n",
    "- Se√±al de identidad biom√©trica\n",
    "\n",
    "LSTM y GRU pueden:\n",
    "\n",
    "‚úî Capturar dependencias largas entre latidos \n",
    "‚úî Aprender la morfolog√≠a completa sin extracci√≥n manual \n",
    "‚úî Ser robustas a ruido y artefactos del ECG   \n",
    "‚úî Trabajar con secuencias cortas o largas  \n",
    "‚úî Entrenar modelos end-to-end \n",
    "---\n",
    "\n",
    "# II. Papers seleccionados sobre LSTM/GRU aplicados a ECG\n",
    "\n",
    "A continuaci√≥n, se explican **tres papers**, resaltando especialmente **c√≥mo implementan LSTM o GRU** y **por qu√© funcionan bien en su aplicaci√≥n**.\n",
    "\n",
    "---\n",
    "\n",
    "# üìò **PAPER 1: Kim & Pyun (2020) ‚Äî BiLSTM + Late Fusion para identificaci√≥n ECG** [4]\n",
    "\n",
    "**Modelo:** Deep Recurrent Neural Network con **3 capas BiLSTM**  \n",
    "**Problema:** Autenticaci√≥n biom√©trica de personas usando ECG  \n",
    "**Por qu√© usan BiLSTM:**  \n",
    "- El ECG contiene informaci√≥n que depende del pasado y ligeramente del futuro (pico T influenciado por QRS anterior)  \n",
    "- Una LSTM bidireccional analiza la se√±al ‚Äúhacia adelante y hacia atr√°s‚Äù, enriqueciendo la representaci√≥n  \n",
    "\n",
    "---\n",
    "\n",
    "## üß© Explicaci√≥n ampliada del uso de LSTM en este paper\n",
    "\n",
    "### 1. Preprocesamiento  \n",
    "Los autores aplican:\n",
    "\n",
    "- Filtro derivativo para resaltar QRS  \n",
    "- Media m√≥vil para suavizar  \n",
    "- Normalizaci√≥n min-max  \n",
    "- Segmentaci√≥n por latido usando R-peaks  \n",
    "\n",
    "Esto permite que la LSTM reciba secuencias ‚Äúlimpias‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Arquitectura BiLSTM m√°s detallada\n",
    "\n",
    "Cada capa BiLSTM procesa:\n",
    "\n",
    "- Secuencia forward ‚Üí aprende progresi√≥n temporal normal del latido  \n",
    "- Secuencia backward ‚Üí aprende simetr√≠as, fin de onda T, retorno a baseline  \n",
    "\n",
    "La salida de ambas direcciones se combina, lo cual permite:\n",
    "\n",
    "- Mayor discriminaci√≥n entre sujetos  \n",
    "- Aprendizaje robusto ante variabilidad intra-individuo  \n",
    "- No requiere extracci√≥n de caracter√≠sticas manuales  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Late Fusion  \n",
    "El modelo produce una predicci√≥n por timestep y luego realiza un **promedio ponderado**.  \n",
    "Esto:\n",
    "\n",
    "- Suaviza variaciones inesperadas  \n",
    "- Aumenta la estabilidad de la clasificaci√≥n  \n",
    "- Reduce el impacto de ruido o latidos at√≠picos  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. Resultados  \n",
    "- **100% accuracy** en NSRDB  \n",
    "- **99.8% accuracy** en MITDB  \n",
    "- Mejores resultados que CNN, SVM y RNN tradicionales  \n",
    "\n",
    "---\n",
    "\n",
    "### ‚úî En este paper, el LSTM funciona porque:\n",
    "- Captura *patrones personales √∫nicos* del ECG  \n",
    "- Modela relaciones temporales finas entre latidos  \n",
    "- Puede trabajar con secuencias cortas (muy √∫til en biometr√≠a real-time)\n",
    "\n",
    "---\n",
    "\n",
    "# üìò **PAPER 2: Satheeswaran et al. (2024) ‚Äî LSTM para clasificaci√≥n de arritmias** [5]\n",
    "\n",
    "**Modelo:** LSTM cl√°sico dentro de una arquitectura RNN  \n",
    "**Problema:** Clasificaci√≥n de arritmias del MIT-BIH  \n",
    "**Por qu√© usan LSTM:** Las anormalidades card√≠acas se manifiestan como alteraciones en los intervalos y morfolog√≠a temporal.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Explicaci√≥n ampliada del uso de LSTM en este paper\n",
    "\n",
    "### 1. Preprocesamiento  \n",
    "Incluye:\n",
    "\n",
    "- Filtros de ruido  \n",
    "- Normalizaci√≥n  \n",
    "- Segmentaci√≥n basada en ventana  \n",
    "- Preparaci√≥n de latidos independientes  \n",
    "\n",
    "La LSTM recibe entradas de longitudes estandarizadas.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. La LSTM como n√∫cleo secuencial\n",
    "\n",
    "La LSTM aprende:\n",
    "\n",
    "- Variaci√≥n en intervalos RR (indicador clave de arritmias)  \n",
    "- Cambios en duraci√≥n QRS  \n",
    "- Aparici√≥n de latidos ventriculares prematuros  \n",
    "- Morfolog√≠a P an√≥mala  \n",
    "\n",
    "La capacidad de memoria permite distinguir:\n",
    "\n",
    "- Latidos **normales**  \n",
    "- Latidos **supraventriculares anormales**  \n",
    "- Latidos **ventriculares**  \n",
    "- Latidos peligrosos como R-on-T  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Resultados  \n",
    "- **98‚Äì99% accuracy**  \n",
    "- Excelente recall en clases minoritarias  \n",
    "- LSTM > RNN simple  \n",
    "\n",
    "---\n",
    "\n",
    "### ‚úî En este paper, el LSTM funciona porque:\n",
    "- Aprende dependencias temporales largas (comportamiento entre latidos sucesivos)  \n",
    "- Reduce necesidad de feature engineering  \n",
    "- Puede adaptarse a ruido y se√±ales incompletas  \n",
    "\n",
    "---\n",
    "\n",
    "# üìò **PAPER 3: Yun Ju et al. (2019) ‚Äî Deep Bidirectional GRU (DBGRU)** [6]\n",
    "\n",
    "**Modelo:** 6 capas de **Bidirectional GRU**  \n",
    "**Problema:** Clasificar **23 tipos** de arritmias (tarea muy dif√≠cil)  \n",
    "**Por qu√© usan GRU bidireccional:**  \n",
    "- GRU es m√°s ligero que LSTM ‚Üí se pueden usar m√°s capas profundas  \n",
    "- Permite analizar secuencias largas sin costos computacionales excesivos  \n",
    "\n",
    "---\n",
    "\n",
    "## üß© Explicaci√≥n ampliada del uso de GRU en este paper\n",
    "\n",
    "### 1. PCA como preprocesamiento  \n",
    "Reduce ruido y dimensionalidad ‚Üí mejora entrada a la GRU.  \n",
    "Esto es importante porque se√±ales MIT-BIH contienen artefactos.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Arquitectura GRU de 6 capas\n",
    "\n",
    "- 3 capas GRU bidireccional de 256 unidades  \n",
    "- 3 capas GRU bidireccional de 128 unidades  \n",
    "- Dropout para evitar overfitting  \n",
    "- Fully connected + Softmax  \n",
    "\n",
    "La GRU captura:\n",
    "\n",
    "- Dependencias temporales largas  \n",
    "- Cambios en secuencia P-QRS-T  \n",
    "- Anomal√≠as espec√≠ficas de las 23 clases  \n",
    "\n",
    "---\n",
    "\n",
    "### 3. Ventaja clave de GRU  \n",
    "Al ser m√°s simples que LSTM:\n",
    "\n",
    "- Entrenan m√°s r√°pido  \n",
    "- Se pueden apilar m√°s capas  \n",
    "- Previenen overfitting por exceso de par√°metros  \n",
    "- Funcionan mejor en datasets grandes o con secuencias largas  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. Resultados  \n",
    "- **99.51% accuracy** (train)  \n",
    "- **97.86% accuracy** (test)  \n",
    "- Super√≥ a:\n",
    "  - Unidirectional LSTM  \n",
    "  - Unidirectional GRU  \n",
    "  - CNN  \n",
    "  - DNN  \n",
    "\n",
    "---\n",
    "\n",
    "### ‚úî En este paper, GRU funciona porque:\n",
    "- Maneja mejor secuencias largas multiclase  \n",
    "- Es m√°s eficiente que LSTM para modelos profundos  \n",
    "- Capta patrones temporales relevantes con menos complejidad  \n",
    "\n",
    "---\n",
    "\n",
    "# III.ü©∫ Repositorios de GitHub que utilizan LSTM/GRU y son aplicados a ECG\n",
    "\n",
    "# ## *1. Notebook LSTM ‚Äî Clasificaci√≥n de Se√±ales ECG*\n",
    "Link github: https://github.com/AlTheMan/ECG-Classifier-LSTM\n",
    "DATASET:  https://www.nature.com/articles/s41597-020-0495-6\n",
    "\n",
    "### *üéØ Objetivo*\n",
    "\n",
    "Entrenar un modelo basado en *LSTM* para clasificar se√±ales ECG, aprendiendo autom√°ticamente patrones temporales y morfol√≥gicos del coraz√≥n sin necesidad de extracci√≥n manual de caracter√≠sticas.\n",
    "\n",
    "### *üìÇ Base de datos utilizada*\n",
    "\n",
    "El notebook carga un dataset que contiene:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Se√±ales ECG segmentadas en *ventanas temporales*.\n",
    "‚Ä¢‚Å†  ‚Å†Cada ventana representa un *latido* o un fragmento de 1‚Äì3 latidos.\n",
    "‚Ä¢‚Å†  ‚Å†Las muestras est√°n en formato:\n",
    "\n",
    "  \n",
    "‚Å†‚ÄØ  (timesteps, 1) ‚Üí se√±al ECG unidimensional\n",
    "  ‚ÄØ‚Å†\n",
    "‚Ä¢‚Å†  ‚Å†Las etiquetas corresponden a clases de arritmias o identificaci√≥n de individuos.\n",
    "\n",
    "La data se divide en:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†*Entrenamiento (train)*\n",
    "‚Ä¢‚Å†  ‚Å†*Validaci√≥n (dev)*\n",
    "‚Ä¢‚Å†  ‚Å†*Prueba (test)*\n",
    "\n",
    "\n",
    "### * Procesamiento de datos*\n",
    "\n",
    "El notebook realiza:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†*Normalizaci√≥n* de amplitud\n",
    "‚Ä¢‚Å†  ‚Å†*Segmentaci√≥n en ventanas* (fijas o basadas en picos R)\n",
    "‚Ä¢‚Å†  ‚Å†Reestructuraci√≥n a formato requerido por LSTM:\n",
    "\n",
    "\n",
    "(samples, timesteps, features=1)\n",
    "\n",
    "\n",
    "\n",
    "### *üß† Arquitectura LSTM*\n",
    "\n",
    "El modelo se basa en:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†1 o m√°s capas *LSTM* para capturar dependencias temporales largas\n",
    "‚Ä¢‚Å†  ‚Å†Capas densas finales para la clasificaci√≥n\n",
    "‚Ä¢‚Å†  ‚Å†Entrenamiento con *Adam* y funci√≥n de p√©rdida *categorical_crossentropy*\n",
    "\n",
    "El LSTM analiza la se√±al muestra por muestra, aprendiendo patrones como:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†forma del complejo QRS\n",
    "‚Ä¢‚Å†  ‚Å†ondas P y T\n",
    "‚Ä¢‚Å†  ‚Å†intervalos temporales entre latidos (RR)\n",
    "\n",
    "\n",
    "### *üìä Resultado del notebook*\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Entrenamiento completo con seguimiento de m√©tricas\n",
    "‚Ä¢‚Å†  ‚Å†Gr√°ficas de p√©rdida y precisi√≥n\n",
    "‚Ä¢‚Å†  ‚Å†Evaluaci√≥n en test\n",
    "‚Ä¢‚Å†  ‚Å†Modelo final entrenado para clasificaci√≥n ECG\n",
    "\n",
    "\n",
    "# ## *2. Script GRU (‚Å†‚ÄØgru.py‚ÄØ‚Å†) ‚Äî Clasificaci√≥n Multietiqueta de ECG*\n",
    "link github: https://github.com/HemaxiN/DL_ECG_Classification/blob/main/cnn_gru.py\n",
    "DATASET: https://physionet.org/content/ptb-xl/1.0.1/\n",
    "### *üéØ Objetivo*\n",
    "\n",
    "Entrenar un modelo *GRU* para clasificaci√≥n *multietiqueta* (4 clases) utilizando se√±ales ECG multicanal (*3 derivaciones*), incluyendo optimizaci√≥n de umbrales y m√©tricas cl√≠nicas reales (sensibilidad/especificidad).\n",
    "\n",
    "\n",
    "\n",
    "## *üìÇ Base de datos utilizada*\n",
    "\n",
    "Cargada mediante ‚Å†‚ÄØDataset_for_RNN‚ÄØ‚Å†:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Cada muestra tiene forma:\n",
    "\n",
    "\n",
    "X ‚Üí (1000 timesteps, 3 features)\n",
    "y ‚Üí (4 etiquetas binarias)\n",
    "\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Dataset dividido en:\n",
    "\n",
    "  * *Train* (batch_size=512)\n",
    "  * *Validation*\n",
    "  * *Validation para thresholds*\n",
    "  * *Test*\n",
    "\n",
    "Las clases est√°n desbalanceadas, por ello se calculan *pesos por clase*.\n",
    "\n",
    "\n",
    "## *Procesamiento de datos*\n",
    "\n",
    "La data ya viene preprocesada desde la carpeta ‚Å†‚ÄØdata_for_rnn‚ÄØ‚Å†, pero el script realiza:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Reorganizaci√≥n de tensores para secuencias GRU\n",
    "‚Ä¢‚Å†  ‚Å†Carga por batches\n",
    "‚Ä¢‚Å†  ‚Å†Aplicaci√≥n de ‚Å†‚ÄØclass_weights‚ÄØ‚Å†\n",
    "‚Ä¢‚Å†  ‚Å†Preparaci√≥n para clasificaci√≥n multietiqueta con BCEWithLogitsLoss\n",
    "\n",
    "\n",
    "## *üß† Arquitectura GRU*\n",
    "\n",
    "El modelo implementa:\n",
    "\n",
    "‚Å†‚ÄØpython\n",
    "nn.GRU(input_size=3,\n",
    "       hidden_size=128,\n",
    "       num_layers=2,\n",
    "       dropout=0.3,\n",
    "       batch_first=True,\n",
    "       bidirectional=True/False)\n",
    "‚ÄØ‚Å†\n",
    "\n",
    "Salida final:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Se usa el √∫ltimo timestep (o combinaci√≥n bidireccional)\n",
    "‚Ä¢‚Å†  ‚Å†Pasa a ‚Å†‚ÄØLinear(hidden_size * d ‚Üí 4)‚ÄØ‚Å†\n",
    "‚Ä¢‚Å†  ‚Å†Activaci√≥n sigmoide durante predicci√≥n\n",
    "\n",
    "El GRU aprende relaciones temporales en las derivaciones del ECG, pero con menor complejidad que LSTM.\n",
    "\n",
    "---\n",
    "\n",
    "## * Entrenamiento*\n",
    "\n",
    "Incluye:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Optimizaci√≥n con Adam o SGD\n",
    "‚Ä¢‚Å†  ‚Å†Early stopping\n",
    "‚Ä¢‚Å†  ‚Å†Guardado del mejor modelo seg√∫n validaci√≥n\n",
    "‚Ä¢‚Å†  ‚Å†C√°lculo de p√©rdida por epoch\n",
    "\n",
    "---\n",
    "\n",
    "## *üîé Optimizaci√≥n de umbrales*\n",
    "\n",
    "El script calcula un umbral √≥ptimo por clase usando:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Curva ROC\n",
    "‚Ä¢‚Å†  ‚Å†G-Mean = ‚àö(TPR √ó (1 ‚Äì FPR))\n",
    "‚Ä¢‚Å†  ‚Å†Threshold por clase para mejorar:\n",
    "\n",
    "  * Sensibilidad\n",
    "  * Especificidad\n",
    "\n",
    "---\n",
    "\n",
    "## *üìä Evaluaci√≥n final*\n",
    "\n",
    "El modelo entrega:\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†Matriz (TP, FN, FP, TN) por clase\n",
    "‚Ä¢‚Å†  ‚Å†Sensibilidad por enfermedad\n",
    "‚Ä¢‚Å†  ‚Å†Especificidad por enfermedad\n",
    "‚Ä¢‚Å†  ‚Å†AUROC por clase\n",
    "‚Ä¢‚Å†  ‚Å†Resultados guardados en archivo ‚Å†‚ÄØ.txt‚ÄØ‚Å†\n",
    "\n",
    "---\n",
    "\n",
    "# ## *Resumen General*\n",
    "\n",
    "‚Ä¢‚Å†  ‚Å†*LSTM Notebook* ‚Üí Clasificaci√≥n basada en morfolog√≠a ECG, un enfoque m√°s cl√°sico, ideal para secuencias largas y dependencias complejas.\n",
    "‚Ä¢‚Å†  ‚Å†*GRU Script* ‚Üí Clasificaci√≥n multietiqueta avanzada, optimizada, con umbrales personalizados y enfoque multicanal. GRU ofrece menor costo computacional con rendimiento comparable.\n",
    "---\n",
    "\n",
    "# ‚úî Conclusi√≥n general\n",
    "\n",
    "Los tres papers demuestran:\n",
    "\n",
    "- **LSTM ‚Üí mejor para biometr√≠a y an√°lisis fino de morfolog√≠a temporal**  \n",
    "- **GRU ‚Üí mejor para modelos profundos o secuencias largas con m√∫ltiples clases**  \n",
    "- Ambos modelos pueden superar 97‚Äì100% de precisi√≥n  \n",
    "- Son adecuados para aplicaciones reales: biometr√≠a, diagn√≥stico y monitoreo en tiempo real  \n",
    "\n",
    "\n",
    "---\n",
    "# Referencias:\n",
    "\n",
    "[1] S. Hochreiter and J. Schmidhuber, ‚ÄúLong Short-Term Memory,‚Äù Neural Computation, vol. 9, no. 8, pp. 1735‚Äì1780, 1997. Disponible en: https://www.bioinf.jku.at/publications/older/2604.pdf\n",
    "[2] K. Cho et al., ‚ÄúLearning Phrase Representations using RNN Encoder‚ÄìDecoder for Statistical Machine Translation,‚Äù in Proc. EMNLP, 2014, pp. 1724‚Äì1734. Disponible en: https://arxiv.org/abs/1406.1078\n",
    "[3] I. Goodfellow, Y. Bengio, and A. Courville, *Deep Learning*.MIT Press, 2016.  \n",
    "Disponible en: https://www.deeplearningbook.org/\n",
    "[4] B.-H. Kim and J.-Y. Pyun, ‚ÄúECG Identification for Personal Authentication Using LSTM-Based Deep Recurrent Neural Networks,‚Äù Sensors, vol. 20, no. 11, pp. 3069, May 2020. Disponible en:https://www.mdpi.com/1424-8220/20/11/3069\n",
    "[5] V. Satheeswaran, A. A. Al-Shargabi, S. Alshargabi, and M. Al-Turjman, ‚ÄúDeep Learning Based Classification of ECG Signals Using RNN-LSTM Mechanism,‚Äù Journal of Electrical Engineering, Electronic Control Management and Information Technology, vol. 6, no. 2, pp. 1‚Äì12, 2024. Disponible en: https://jeeemi.org/index.php/jeeemi/article/view/496\n",
    "[6] Y. Ju, M. Zhang, and H. Zhu, ‚ÄúStudy on a New Deep Bidirectional GRU Network for Electrocardiogram Signals Classification,‚Äù in Proc. 3rd Int. Conf. Comput. Eng., Inf. Sci. Appl. Technol. (ICCIA), 2019, pp. 355‚Äì359. Disponible en (PDF):https://www.researchgate.net/publication/334658737_Study_on_a_New_Deep_Bidirectional_GRU_Network_for_Electrocardiogram_Signals_Classification \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
