{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48032235",
   "metadata": {},
   "source": [
    "# **1Ô∏è‚É£ Introducci√≥n**\n",
    "El ictus es una de las principales causas de discapacidad a nivel mundial, generando secuelas motoras que requieren largos periodos de rehabilitaci√≥n. El seguimiento de la recuperaci√≥n suele basarse en evaluaciones cl√≠nicas presenciales, escalas funcionales y observaci√≥n subjetiva del desempe√±o del paciente, lo que limita la frecuencia y objetividad de la monitorizaci√≥n [1].\n",
    "\n",
    "La electromiograf√≠a (EMG) de superficie permite registrar la actividad el√©ctrica de los m√∫sculos y, a partir de ella, inferir la ejecuci√≥n de gestos motores. Sistemas de reconocimiento de gestos basados en EMG han demostrado ser √∫tiles en control prot√©sico, interfaces hombre-m√°quina y rehabilitaci√≥n, pero la mayor√≠a de soluciones completas son costosas, cerradas o poco adaptables a contextos de recursos limitados [2][3].\n",
    "\n",
    "Se utilizan los algoritmos KNN y SVM para reconocer gestos con alta precisi√≥n con poca o gran cantidad de datos para la clasificaci√≥n.\n",
    "\n",
    "En este contexto, resulta relevante dise√±ar un sistema sencillo, reproducible y de bajo costo que procese se√±ales EMG del antebrazo, segmente gestos de mano y permita entrenar clasificadores supervisados. Este tipo de herramienta podr√≠a emplearse como soporte para el seguimiento de la recuperaci√≥n motora en pacientes con ictus, tanto en entornos cl√≠nicos como en el hogar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aebccb",
   "metadata": {},
   "source": [
    "# **2Ô∏è‚É£ Problem√°tica**\n",
    "\n",
    "## ***2Ô∏è‚É£.1Ô∏è‚É£Problem√°tica General:*** \n",
    "Los pacientes con ictus necesitan sistemas asequibles que permitan realizar un seguimiento objetivo y frecuente de la recuperaci√≥n motora de la mano; sin embargo, las soluciones de reconocimiento de gestos basadas en EMG disponibles en el mercado no son ampliamente accesibles por su costo, requerimientos de hardware y complejidad de uso.\n",
    "## ***2Ô∏è‚É£.2Ô∏è‚É£Problem√°ticas Espec√≠ficas:***\n",
    "\n",
    "- Se requiere un flujo de procesamiento que segmente correctamente un registro EMG continuo en ventanas que correspondan a gestos espec√≠ficos, manteniendo sincron√≠a temporal y etiquetas claras.\n",
    "- Es necesario generar un conjunto de caracter√≠sticas a partir de los canales EMG que sea adecuado para entrenar clasificadores supervisados de baja complejidad computacional (por ejemplo, K-NN o SVM), con miras a implementaciones futuras en hardware de bajo costo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733046c2",
   "metadata": {},
   "source": [
    "# **3Ô∏è‚É£ Propuesta de soluci√≥n**\n",
    "El sistema BioGest EMG propone generar un sistema que ayude en la rehabilitaci√≥n motora mediante el uso de las se√±ales electromiogr√°ficas (EMG), donde con las se√±ales obtenidas se podr√°n reconocer 3 gestos simples de la mano del paciente post-ictus (Extensi√≥n de mano,Pu√±o y Desviaci√≥n ulnar ( girar la mano a la izquierda como haciendo un hola)), proponiendo una herramienta de bajo costo y f√°cil uso, integrando hardware econ√≥mico, procesamiento digital de se√±ales y algoritmos de aprendizaje autom√°tico.\n",
    "\n",
    "Se busca automatizar la evaluaci√≥n del progreso post-ictus, registrando, procesando y clasificando los movimientos de la mano en tiempo real durante las terapias, brindando retroalimentaci√≥n visual y estad√≠stica sobre el progreso del paciente para una recuperaci√≥n m√°s eficiente.\n",
    "\n",
    "Basado en estudios recientes, se demuestra la viabilidad del reconocimiento de gestos mediante sEMG multicanal, tanto con modelos de machine learning tradicionales (Random Forest, SVM, kNN), como con enfoques de deep learning basados en CNN y espectrogramas [4].\n",
    "\n",
    "El flujo de trabajo que sigue la propuesta es:\n",
    "- *Segmentaci√≥n temporal y generaci√≥n de archivos por gesto:* Se parte de un archivo CSV con todos los canales EMG de un experimento, en donde cada experimento se organiza en ciclos que contienen 10 gestos; a su vez, cada gesto ocupa una ventana de 10 s: 4 s de reposo inicial y 6 s de gesto activo. El script automatiza el corte de un ciclo en 10 ventanas de 10 s, una por gesto, combinando todos los canales EMG en una √∫nica se√±al y generando archivos separados. \n",
    "- *Extracci√≥n de caracter√≠sticas y clasificaci√≥n:* A partir de cada archivo de gesto se pueden calcular caracter√≠sticas cl√°sicas en el dominio temporal (RMS, valor absoluto medio, varianza, etc.) y/o en frecuencia. Se utiliza un clasificador supervisado, como K-NN o SVM, para distinguir entre 3 gestos de mano a partir de estas caracter√≠sticas. El objetivo es obtener un porcentaje de clasificaci√≥n correcto suficientemente alto como para que el sistema sea √∫til en un escenario de seguimiento motor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6aa3f6",
   "metadata": {},
   "source": [
    "![Imagen de proyecto 1](ISB_Proyecto_1.jpeg)\n",
    "Fig 01 - P√°gina donde se realiz√≥ el trabajo: Edge Impulse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8407d7",
   "metadata": {},
   "source": [
    "![Imagen de proyecto 2](ISB_Proyecto_2.jpeg)\n",
    "Fig 02 - Par√°metros de procesamiento de data: espectrograma y su resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c51600",
   "metadata": {},
   "source": [
    "![Imagen de proyecto 3](ISB_Proyecto_3.jpeg)\n",
    "\n",
    "Fig 03 - Par√°metros de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3853965e",
   "metadata": {},
   "source": [
    "# **4Ô∏è‚É£ C√≥digo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a8e53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ==========================\n",
    "# RUTAS\n",
    "# ==========================\n",
    "INPUT_FILE = \"/Users/lucianatarazona/Desktop/proyecto/csv/1_filtered.csv\"\n",
    "OUT_DIR    = \"/Users/lucianatarazona/Desktop/proyecto/participante_1_2\"\n",
    "\n",
    "# ==========================\n",
    "# PAR√ÅMETROS\n",
    "# ==========================\n",
    "FS = 2000          # Frecuencia de muestreo (Hz)  <-- c√°mbiala si es otra\n",
    "NUM_GESTURES = 10  # 10 gestos en el ciclo\n",
    "REST_SEC     = 4.0 # 4 s de reposo inicial\n",
    "GESTURE_SEC  = 6.0 # 6 s de gesto\n",
    "GESTO_TOTAL_SEC = REST_SEC + GESTURE_SEC  # 10 s √∫tiles por gesto\n",
    "\n",
    "# ==========================\n",
    "# LEER CSV COMPLETO\n",
    "# ==========================\n",
    "# header=None para no perder la primera fila de datos\n",
    "df = pd.read_csv(INPUT_FILE, header=None)\n",
    "\n",
    "# Nombrar columnas como ch1, ch2, ...\n",
    "num_channels = df.shape[1]\n",
    "channel_names = [f\"ch{i+1}\" for i in range(num_channels)]\n",
    "df.columns = channel_names\n",
    "\n",
    "total_samples = len(df)\n",
    "total_sec = total_samples / FS\n",
    "\n",
    "# Sabemos que hay 5 ciclos en total\n",
    "NUM_CYCLES_TOTAL = 5\n",
    "cycle_sec = total_sec / NUM_CYCLES_TOTAL   # duraci√≥n de 1 ciclo (= 10 gestos de 10 s + 4 s de reposo final)\n",
    "\n",
    "print(f\"Duraci√≥n total: {total_sec:.2f} s\")\n",
    "print(f\"Duraci√≥n estimada de 1 ciclo: {cycle_sec:.2f} s\")\n",
    "\n",
    "# SOLO usamos el primer ciclo\n",
    "cycle_start_sec = 0.0\n",
    "\n",
    "# Crear carpeta de salida\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# CORTAR SOLO 1 CICLO (10 GESTOS)\n",
    "# ==========================\n",
    "for g in range(NUM_GESTURES):\n",
    "    # Inicio del bloque √∫til (reposo inicial + gesto) de este gesto\n",
    "    # Los gestos se suceden cada 10 s dentro del ciclo:\n",
    "    # [4s reposo + 6s gesto] * 10  +  4s reposo final (que ignoramos)\n",
    "    gesture_start_sec = cycle_start_sec + g * GESTO_TOTAL_SEC\n",
    "    gesture_end_sec   = gesture_start_sec + GESTO_TOTAL_SEC  # 10 s totales\n",
    "\n",
    "    # Pasar a √≠ndices\n",
    "    start_idx = int(round(gesture_start_sec * FS))\n",
    "    end_idx   = int(round(gesture_end_sec   * FS))\n",
    "\n",
    "    # Seguridad\n",
    "    start_idx = max(start_idx, 0)\n",
    "    end_idx   = min(end_idx, total_samples)\n",
    "\n",
    "    segment = df.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "\n",
    "    # ==========================\n",
    "    # COMBINAR CANALES ‚Üí EMG (RMS)\n",
    "    # ==========================\n",
    "    # Si solo quieres los 4 primeros canales, descomenta esta l√≠nea:\n",
    "    # segment_for_emg = segment.iloc[:, :4]\n",
    "    segment_for_emg = segment  # usa todas las columnas como EMG\n",
    "\n",
    "    # RMS por muestra\n",
    "    emg_signal = np.sqrt((segment_for_emg ** 2).sum(axis=1))\n",
    "\n",
    "    # ==========================\n",
    "    # TIMESTAMP EN ms (0‚Äì10 s)\n",
    "    # ==========================\n",
    "    n = len(emg_signal)\n",
    "    dt_ms = 1000.0 / FS      # intervalo en milisegundos\n",
    "    timestamps = np.arange(n) * dt_ms\n",
    "\n",
    "    out_df = pd.DataFrame({\n",
    "        \"timestamp\": timestamps,\n",
    "        \"emg\": emg_signal\n",
    "    })\n",
    "\n",
    "    # Guardar archivo de este gesto (solo 1 ciclo, 10 s)\n",
    "    filename = os.path.join(OUT_DIR, f\"gesture_{g+1:02d}.csv\")\n",
    "    out_df.to_csv(filename, index=False)\n",
    "    print(f\"Gesto {g+1} guardado en: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd9201",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.1Ô∏è‚É£ Importaci√≥n de librer√≠as y definici√≥n de rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9533f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "INPUT_FILE = \"....../1_filtered.csv\"\n",
    "OUT_DIR    = \"....../participante_1_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3553b1",
   "metadata": {},
   "source": [
    "- Se importan pandas y numpy para manejar datos y operaciones num√©ricas, y os para gestionar rutas y carpetas.\n",
    "\n",
    "- INPUT_FILE apunta al CSV con la se√±al EMG ya filtrada; OUT_DIR es la carpeta donde se guardar√°n los gestos segmentados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9530fff",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.2Ô∏è‚É£ Definici√≥n de par√°metros del experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6aef75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "FS = 2000          # Frecuencia de muestreo (Hz)\n",
    "NUM_GESTURES = 10  # 10 gestos en el ciclo\n",
    "REST_SEC     = 4.0 # 4 s de reposo inicial\n",
    "GESTURE_SEC  = 6.0 # 6 s de gesto\n",
    "GESTO_TOTAL_SEC = REST_SEC + GESTURE_SEC  # 10 s por gesto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06ef82",
   "metadata": {},
   "source": [
    "- FS fija la frecuencia de muestreo en 2000 Hz.\n",
    "\n",
    "- NUM_GESTURES indica que en un ciclo hay 10 gestos.\n",
    "\n",
    "- Cada gesto est√° compuesto por 4 s de reposo y 6 s de ejecuci√≥n, sumando 10 s (GESTO_TOTAL_SEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b785448",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.3Ô∏è‚É£ Lectura del archivo CSV y nombrado de canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52832312",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_FILE, header=None)\n",
    "num_channels = df.shape[1]\n",
    "channel_names = [f\"ch{i+1}\" for i in range(num_channels)]\n",
    "df.columns = channel_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c8efbd",
   "metadata": {},
   "source": [
    "- pd.read_csv carga todo el registro EMG, que inicialmente no tiene encabezados.\n",
    "\n",
    "- Se cuentan las columnas (num_channels) y se les asignan nombres gen√©ricos (ch1, ch2, ..., chN), representando cada uno de los canales EMG registrados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa7310",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.4Ô∏è‚É£ C√°lculo de duraci√≥n total y del ciclo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c377c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_samples = len(df)\n",
    "total_sec = total_samples / FS\n",
    "\n",
    "NUM_CYCLES_TOTAL = 5\n",
    "cycle_sec = total_sec / NUM_CYCLES_TOTAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90196a3e",
   "metadata": {},
   "source": [
    "- total_samples es el n√∫mero de muestras en todo el registro, y total_sec su duraci√≥n en segundos.\n",
    "\n",
    "- Se asume que el experimento contiene 5 ciclos completos (NUM_CYCLES_TOTAL), por lo que la duraci√≥n de cada ciclo se estima como cycle_sec = total_sec / 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ec317",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.5Ô∏è‚É£ Selecci√≥n del ciclo a procesar y creaci√≥n de carpeta de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc98d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cycle_start_sec = 0.0\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b3b520",
   "metadata": {},
   "source": [
    "- cycle_start_sec indica desde qu√© segundo del registro se toma el ciclo (en este caso, se usa el primer ciclo, empezando en 0 s).\n",
    "\n",
    "- os.makedirs crea la carpeta de salida si no existe (exist_ok=True evita errores si la carpeta ya fue creada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b137ed",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.6Ô∏è‚É£ Bucle principal de segmentaci√≥n de gestos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9ff26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for g in range(NUM_GESTURES):\n",
    "    gesture_start_sec = cycle_start_sec + g * GESTO_TOTAL_SEC\n",
    "    gesture_end_sec   = gesture_start_sec + GESTO_TOTAL_SEC\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c987a3",
   "metadata": {},
   "source": [
    "- Se recorre cada gesto g de 0 a 9 (10 gestos).\n",
    "\n",
    "- Para cada gesto se calcula el tiempo de inicio (gesture_start_sec) y fin (gesture_end_sec) dentro del ciclo, separados por bloques de 10 s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba02f6",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.7Ô∏è‚É£ Conversi√≥n de tiempos a √≠ndices de muestra y corte de la se√±al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50b705",
   "metadata": {},
   "source": [
    "- Se multiplican los tiempos por la frecuencia de muestreo para obtener √≠ndices en la se√±al (start_idx, end_idx).\n",
    "\n",
    "- Se aplican l√≠mites de seguridad para no salir del rango del dataframe.\n",
    "\n",
    "- segment contiene la porci√≥n de la se√±al correspondiente a los 10 s (reposo + gesto) para ese gesto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79287ee6",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.8Ô∏è‚É£ Combinaci√≥n de canales EMG en una sola se√±al (tipo RMS/vector magnitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ecd63d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "segment_for_emg = segment  # se usan todos los canales\n",
    "emg_signal = np.sqrt((segment_for_emg ** 2).sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa86dd",
   "metadata": {},
   "source": [
    "- segment_for_emg selecciona los canales a combinar. En el comentario se indica que, si se desea, se pueden usar solo algunos canales (por ejemplo, los 4 primeros).\n",
    "\n",
    "- Se calcula, muestra a muestra, la ra√≠z cuadr√°tica de la suma de cuadrados de los canales. Esto genera una se√±al emg_signal que representa la magnitud global de la actividad EMG en el antebrazo, reduciendo la dimensionalidad y facilitando el procesamiento posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f02d13",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.9Ô∏è‚É£ Generaci√≥n de marcas de tiempo y construcci√≥n del DataFrame de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2c519",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "n = len(emg_signal)\n",
    "dt_ms = 1000.0 / FS\n",
    "timestamps = np.arange(n) * dt_ms\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    \"timestamp\": timestamps,\n",
    "    \"emg\": emg_signal\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69061d",
   "metadata": {},
   "source": [
    "- dt_ms es el intervalo de tiempo en milisegundos entre muestras.\n",
    "\n",
    "- timestamps es un vector que va de 0 a (n-1)¬∑dt_ms, que marca el tiempo de cada muestra dentro de la ventana de 10 s.\n",
    "\n",
    "- Se crea un nuevo DataFrame out_df con dos columnas: timestamp (en ms) y emg (magnitud de la se√±al)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04365b4a",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£.üîü Guardado de cada gesto en un archivo CSV independiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c8817",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(OUT_DIR, f\"gesture_{g+1:02d}.csv\")\n",
    "out_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da74db",
   "metadata": {},
   "source": [
    "- Se construye un nombre de archivo para cada gesto (gesture_01.csv, gesture_02.csv, ‚Ä¶, gesture_10.csv).\n",
    "\n",
    "- Cada archivo contiene la se√±al EMG combinada y su marca de tiempo, lista para ser usada en las etapas de extracci√≥n de caracter√≠sticas y entrenamiento del clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a67d4",
   "metadata": {},
   "source": [
    "# **5Ô∏è‚É£ Resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020749e4",
   "metadata": {},
   "source": [
    "![Imagen de proyecto 4](ISB_Proyecto_4.jpeg)\n",
    "\n",
    "Fig 04 - Matriz de confusi√≥n con accuracy y p√©rdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9158f94",
   "metadata": {},
   "source": [
    "![Imagen de proyecto 5](ISB_Proyecto_5.jpeg)\n",
    "\n",
    "Fig 05 - Clasificaci√≥n de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57775810",
   "metadata": {},
   "source": [
    "# **6Ô∏è‚É£ Conclusiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d9c35",
   "metadata": {},
   "source": [
    "El dise√±o e implementaci√≥n del sistema BioGest EMG permiti√≥ validar, en primera instancia, la eficacia del flujo de procesamiento digital desarrollado. El algoritmo de segmentaci√≥n automatizada logr√≥ fragmentar exitosamente los registros continuos en ventanas temporales de 10 segundos, garantizando la sincron√≠a necesaria entre los periodos de reposo y la actividad muscular para la correcta generaci√≥n del conjunto de datos. De igual manera, la estrategia de preprocesamiento basada en la se√±al de magnitud global (RMS) demostr√≥ ser altamente eficiente; al sintetizar la informaci√≥n de m√∫ltiples canales en un √∫nico vector, se redujo significativamente la carga computacional sin comprometer la integridad de la informaci√≥n muscular, lo cual resulta fundamental para la viabilidad de futuras implementaciones en hardware de recursos limitados.\n",
    "\n",
    "Por otro lado, la evaluaci√≥n experimental confirma la capacidad del sistema para mitigar la subjetividad inherente a las evaluaciones cl√≠nicas tradicionales. Al proporcionar un m√©todo objetivo para cuantificar la ejecuci√≥n de gestos funcionales como la extensi√≥n de mano y la desviaci√≥n ulnar, la herramienta facilita un seguimiento m√°s riguroso de la recuperaci√≥n motora en pacientes con secuelas de ictus. Esto se ve respaldado por el desempe√±o de los algoritmos de clasificaci√≥n, cuyos resultados ‚Äîvisualizados en las matrices de confusi√≥n‚Äî evidencian una alta discriminabilidad entre los estados de reposo y los gestos activos, validando as√≠ el uso de modelos supervisados para el monitoreo en entornos de rehabilitaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbac9e4",
   "metadata": {},
   "source": [
    "# **7Ô∏è‚É£ Bibliograf√≠a**\n",
    "\n",
    "[1]M. A. Ozdemir, D. H. Kisa, O. Guren, A. Onan, and A. Akan, ‚ÄúEMG based Hand Gesture Recognition using Deep Learning,‚Äù in 2020 Medical Technologies National Congress (TIPTEKNO), Antalya, Turkey, 2020, pp. 455‚Äì459. doi: 10.1109/TIPTEKNO50054.2020.9299264\n",
    "\n",
    "[2] Ministerio de Salud (MINSA), Accidente cerebrovascular es la primera causa de discapacidad permanente en edad adulta. [En l√≠nea]. Disponible en: https://www.gob.pe/institucion/minsa/noticias/61387-accidente-cerebrovascular-es-la-primera-causa-de-discapacidad-permanente-en-edad-adulta.\n",
    "\n",
    "[3]Ministerio de Salud (MINSA), Minsa: 1 de cada 4 personas sufrir√° un ataque cerebrovascular durante su vida. [En l√≠nea]. Disponible en: https://www.gob.pe/institucion/minsa/noticias/1274851-minsa-1-de-cada-4-personas-sufrira-un-ataque-cerebrovascular-durante-su-vida\n",
    "\n",
    "[4] Asociaci√≥n Da√±o Cerebral Adquirido, ¬øY si la recuperaci√≥n del miembro superior tras un ictus dejara de ser una excepci√≥n?. [En l√≠nea]. Disponible en: https://xn--daocerebral-2db.es/y-si-la-recuperacion-del-miembro-superior-tras-un-ictus-dejara-de-ser-una-excepcion/#:~:text=Una%20secuela%20frecuente,terapeuta%20ocupacional%20en%20la%20introducci%C3%B3n.\n",
    "\n",
    "[5] M. A. Ozdemir, D. H. Kisa, O. Guren, and A. Akan, ‚ÄúDataset for multi-channel surface electromyography (sEMG) signals of hand gestures,‚Äù Mendeley Data, Version 2, Dec. 22, 2021. data: https://data.mendeley.com/datasets/ckwc76xr2z/2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
